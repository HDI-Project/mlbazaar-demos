{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Table Regression + Tuning Demo\n",
    "\n",
    "In this demo, we will learn how to use a simple MLBazaar pipeline in combination\n",
    "with the BTB tuning library to predict housing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging and imports\n",
    "\n",
    "from utils import get_tunables, pprint, setup\n",
    "\n",
    "setup()\n",
    "\n",
    "import numpy as np\n",
    "from btb.tuning import GP\n",
    "from mlblocks import MLPipeline\n",
    "from mlprimitives.datasets import load_boston\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset\n",
    "\n",
    "First we load The Boston Housing Dataset form the MLPrimitives library.\n",
    "\n",
    "The Boston Housing Dataset is a derived from information collected by the U.S. Census Service concerning housing in the area of Boston MA. The following describes the dataset columns:\n",
    "\n",
    "- CRIM - per capita crime rate by town\n",
    "- ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- INDUS - proportion of non-retail business acres per town.\n",
    "- CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "- NOX - nitric oxides concentration (parts per 10 million)\n",
    "- RM - average number of rooms per dwelling\n",
    "- AGE - proportion of owner-occupied units built prior to 1940\n",
    "- DIS - weighted distances to five Boston employment centres\n",
    "- RAD - index of accessibility to radial highways\n",
    "- TAX - full-value property-tax rate per \\$10,000\n",
    "- PTRATIO - pupil-teacher ratio by town\n",
    "- B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "- LSTAT - % lower status of the population\n",
    "- MEDV - Median value of owner-occupied homes in \\$1000's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_boston()\n",
    "\n",
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `X` variable contains the first 13 columns of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01,\n",
       "        6.5750e+00, 6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02,\n",
       "        1.5300e+01, 3.9690e+02, 4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9690e+02, 9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        7.1850e+00, 6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9283e+02, 4.0300e+00]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the `y` variable contains the 14th column, which we will try to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset in train and test\n",
    "\n",
    "We will use the `get_split` function from the dataset object\n",
    "to split the data in two parts:\n",
    "\n",
    "- `X_train` and `y_train` is the data that we will use to tune and fit our pipeline.\n",
    "- `X_test` and `y_test` is the data that we will use to evaluate our pipeline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = dataset.get_splits(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Pipeline\n",
    "\n",
    "In this case we will create a very simple pipeline with only two primitives:\n",
    "\n",
    "- A StandardScaler, that calculates the Z-score of each variable\n",
    "- A Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "primitives = [\n",
    "    \"sklearn.preprocessing.StandardScaler\",\n",
    "    \"sklearn.linear_model.Lasso\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = MLPipeline(primitives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Pipeline\n",
    "\n",
    "Before attempting to tune the pipeline, we will use it with its default hyperparameter\n",
    "values to see how well it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('sklearn.preprocessing.StandardScaler#1', 'with_mean'): True,\n",
       " ('sklearn.preprocessing.StandardScaler#1', 'with_std'): True,\n",
       " ('sklearn.linear_model.Lasso#1', 'copy_X'): True,\n",
       " ('sklearn.linear_model.Lasso#1', 'warm_start'): False,\n",
       " ('sklearn.linear_model.Lasso#1', 'random_state'): None,\n",
       " ('sklearn.linear_model.Lasso#1', 'precompute'): False,\n",
       " ('sklearn.linear_model.Lasso#1', 'normalize'): False,\n",
       " ('sklearn.linear_model.Lasso#1', 'fit_intercept'): True,\n",
       " ('sklearn.linear_model.Lasso#1', 'alpha'): 1.0,\n",
       " ('sklearn.linear_model.Lasso#1', 'max_iter'): 1000,\n",
       " ('sklearn.linear_model.Lasso#1', 'tol'): 0.0001,\n",
       " ('sklearn.linear_model.Lasso#1', 'positive'): False,\n",
       " ('sklearn.linear_model.Lasso#1', 'selection'): 'cyclic'}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_hyperparams = pipeline.get_hyperparameters(flat=True)\n",
    "default_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6935445588519191"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_score = dataset.score(y_test, predictions)\n",
    "default_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for tuning\n",
    "\n",
    "Now we will obtain the list of tunable hyperparameters and their possible ranges\n",
    "from the pipeline object, which we will later on use to tune them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"sklearn.preprocessing.StandardScaler#1\": {\n",
      "        \"with_mean\": {\n",
      "            \"type\": \"bool\",\n",
      "            \"default\": true\n",
      "        },\n",
      "        \"with_std\": {\n",
      "            \"type\": \"bool\",\n",
      "            \"default\": true\n",
      "        }\n",
      "    },\n",
      "    \"sklearn.linear_model.Lasso#1\": {\n",
      "        \"normalize\": {\n",
      "            \"type\": \"bool\",\n",
      "            \"default\": false,\n",
      "            \"description\": \"This parameter is ignored when fit_intercept is set to False. If True, the regressors X will be normalized before regression by subtracting the mean and dividing by the l2-norm.\"\n",
      "        },\n",
      "        \"fit_intercept\": {\n",
      "            \"type\": \"bool\",\n",
      "            \"default\": true,\n",
      "            \"description\": \"Whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations (e.g. data is expected to be already centered).\"\n",
      "        },\n",
      "        \"alpha\": {\n",
      "            \"type\": \"float\",\n",
      "            \"description\": \"Regularization strength. Alpha corresponds to C^-1 in other linear models such as LogisticRegression or LinearSVC. Must be a positive float.\",\n",
      "            \"default\": 1.0,\n",
      "            \"range\": [\n",
      "                0.01,\n",
      "                10.0\n",
      "            ]\n",
      "        },\n",
      "        \"max_iter\": {\n",
      "            \"type\": \"int\",\n",
      "            \"description\": \"The maximum number of iterations\",\n",
      "            \"default\": 1000,\n",
      "            \"range\": [\n",
      "                1,\n",
      "                10000\n",
      "            ]\n",
      "        },\n",
      "        \"tol\": {\n",
      "            \"type\": \"float\",\n",
      "            \"description\": \"The tolerance for the optimization: if the updates are smaller than tol, the optimization code checks the dual gap for optimality and continues until it is smaller than tol.\",\n",
      "            \"default\": 0.0001,\n",
      "            \"range\": [\n",
      "                1e-06,\n",
      "                0.01\n",
      "            ]\n",
      "        },\n",
      "        \"positive\": {\n",
      "            \"type\": \"bool\",\n",
      "            \"description\": \"When set to True, forces the coefficients to be positive.\",\n",
      "            \"default\": false\n",
      "        },\n",
      "        \"selection\": {\n",
      "            \"type\": \"str\",\n",
      "            \"description\": \"If set to \\u2018random\\u2019, a random coefficient is updated every iteration rather than looping over features sequentially by default.\",\n",
      "            \"values\": [\n",
      "                \"cyclic\",\n",
      "                \"random\"\n",
      "            ],\n",
      "            \"default\": \"cyclic\"\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tunable_hyperparameters = pipeline.get_tunable_hyperparameters()\n",
    "pprint(tunable_hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the tuning loop\n",
    "\n",
    "Now we will start using a BTB tuner to try to find the optimal hyperparameter\n",
    "values for this problem, with the goal of improving the default score that\n",
    "we have previously obtained.\n",
    "\n",
    "For this, we will start a tuning loop of 300 iterations where, for each iteration,\n",
    "we will:\n",
    "\n",
    "- Ask the tuner for new hyperparameter values to try\n",
    "- Cross validate the pipeline over the training data using the obtained hyperparameters\n",
    "- Inform the tuner about the score obtained using the proposed hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2012346c844a059fa3ec50a0c61024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Best score so far: 0.33732400114209027\n",
      "1 - Best score so far: 0.5198225258588864\n",
      "18 - Best score so far: 0.5972870399338879\n",
      "56 - Best score so far: 0.6505453962748078\n",
      "97 - Best score so far: 0.6510096455741543\n",
      "223 - Best score so far: 0.6772882922397171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup the tuner\n",
    "tunables = get_tunables(tunable_hyperparameters)\n",
    "tuner = GP(tunables, r_minimum=10)\n",
    "tuner.add(default_hyperparams, default_score)\n",
    "\n",
    "# Set up the KFold splitter\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "# Start the tuning loop\n",
    "best = 0\n",
    "for i in tnrange(300):\n",
    "    params = tuner.propose()\n",
    "    pipeline.set_hyperparameters(params)\n",
    "    \n",
    "    scores = []\n",
    "    for train, test in kfold.split(X_train, y_train):\n",
    "        pipeline.fit(X_train[train], y_train[train])\n",
    "        predictions = pipeline.predict(X_train[test])\n",
    "        scores.append(dataset.score(y_train[test], predictions))\n",
    "    \n",
    "    score = np.mean(scores)\n",
    "    tuner.add(params, score)\n",
    "    \n",
    "    if score > best:\n",
    "        best = score\n",
    "        best_params = params\n",
    "        print(\"{} - Best score so far: {}\".format(i, best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('sklearn.preprocessing.StandardScaler#1', 'with_mean'): True,\n",
       " ('sklearn.preprocessing.StandardScaler#1', 'with_std'): True,\n",
       " ('sklearn.linear_model.Lasso#1', 'normalize'): False,\n",
       " ('sklearn.linear_model.Lasso#1', 'fit_intercept'): True,\n",
       " ('sklearn.linear_model.Lasso#1', 'alpha'): 0.015689893350340295,\n",
       " ('sklearn.linear_model.Lasso#1', 'max_iter'): 5514,\n",
       " ('sklearn.linear_model.Lasso#1', 'tol'): 0.005459799384172081,\n",
       " ('sklearn.linear_model.Lasso#1', 'positive'): False,\n",
       " ('sklearn.linear_model.Lasso#1', 'selection'): 'random'}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the found hyperparameters\n",
    "\n",
    "After the tuning has been finished, we evaluate again the performance of the pipeline\n",
    "over the training data when using the new hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.set_hyperparameters(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7438447686752354"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.score(y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
